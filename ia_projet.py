# -*- coding: utf-8 -*-
"""IA-projet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lu3MuuotS4CaTalzabiPrKIdkVaTQ7EI

# Deep note - Introduction à la quantization

Projet Intelligence Artificielle - Groupe 8 - EFREI

Chloé DESRUE - Marie SAYAG - Manon WIECLAW
"""

from keras.datasets import mnist
from matplotlib import pyplot
import numpy as np
import os

(train_X, train_y), (test_X, test_y) = mnist.load_data()

pyplot.imshow(train_X[1], cmap=pyplot.get_cmap('gray'))
pyplot.show()

from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Conv2D, MaxPooling2D
from keras.layers.core import Dense, Dropout, Activation,Flatten
#import tensorflow_model_optimization as tfmot

print(train_X.shape)

print(test_X.shape)

#import numpy as np
#Reshape et normalisation minMaxScalling

train_X = train_X.reshape(60000, 28, 28, 1)/255  #minmax scalling
train_X.shape

test_X = test_X.reshape(-1, 28, 28, 1)/255  #minmax scalling
test_X.shape

model = Sequential()

model.add(Conv2D(32, kernel_size = (3, 3), activation='relu')) #32 neurone
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Flatten())

model.add(Dense(units = 150, activation='relu',input_shape =[28**2]))
model.add(Dense(units=10, activation='softmax'))

model.compile (loss = 'sparse_categorical_crossentropy', optimizer = "adam", metrics = ['accuracy']) #ou sgd pour optimizer

model.fit(train_X, train_y, epochs=10, validation_data = [test_X, test_y])

model.summary()

"""Accuracy du modèle non quantifié : """

score = model.evaluate(test_X, test_y, verbose=0)

print('Test accuracy:', score[1])

import joblib
joblib.dump(model, 'classification_modele.joblib')

size = os.path.getsize("classification_modele.joblib")
print (size, 'octets')

"""# **Quantization post training**"""

#import joblib
#model = joblib.load('/content/drive/MyDrive/IA/classification_modele.joblib')

import tensorflow as tf
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

#save the model
with open('model.tflite', 'wb') as f:
  f.write(tflite_model)

"""Taille du fichier généré model.tflite : 5.6 Mo"""

converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tf_quant_model = converter.convert()

#save the model
with open('model_optimize.tflite', 'wb') as f:
  f.write(tf_quant_model)

size_post = os.path.getsize("model_optimize.tflite")
print (size_post, 'octet')

"""La taille du fichier généré est plus petite : 1,4 Mo
Optimize.DEFAULT utilise la quantification de plage dynamique

# **Quantization aware training**
"""

! pip install -q tensorflow-model-optimization
import tensorflow_model_optimization as tfmot


qat_model = tfmot.quantization.keras.quantize_model(model)

qat_model.compile (loss = 'sparse_categorical_crossentropy', optimizer = "adam", metrics = ['accuracy']) 
qat_model.summary()

"""Réentraîner votre modèle sur un sous ensemble des modèles sur une ou deux epochs et afficher la performance sur le train et test"""

train_X.max()

X_train_min = train_X[0:1000]
Y_train_min = train_y[0:1000]
print(X_train_min.shape)
print(train_X.shape)

qat_model.fit(X_train_min, Y_train_min, epochs=2, validation_data = [test_X, test_y])

"""## Conversion du modèle avec TFLite"""

converter = tf.lite.TFLiteConverter.from_keras_model(qat_model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_qat_model = converter.convert()

#save the model
with open('QAT.tflite', 'wb') as f:
  f.write(tflite_qat_model)

size_QAT = os.path.getsize("QAT.tflite")
print (size_QAT, 'octet')

"""Taille du modèle obtenu : 1.4 Mo

# Comparer les performances des trois modèles (taille et accuracy)

Calcul de l'accuracy pour le post training :
"""

interpreter = tf.lite.Interpreter("model_optimize.tflite")
interpreter.allocate_tensors()

input_details = interpreter.get_input_details()

output_details = interpreter.get_output_details()

input_details

acc = 0

for i in range (len(test_y)):
  inp = test_X[i].reshape(1, 28, 28, 1).astype("float32")
  interpreter.set_tensor(input_details[0]["index"], inp)

  interpreter.invoke()

  prediction = interpreter.get_tensor(output_details[0]["index"])
  classe = np.argmax(prediction) #plus grande probabilité d'appartenir à cette classe


  if (classe == test_y[i]):
    acc += 1
    

accuracy_post = acc / i

print(accuracy_post)

"""Accuracy des trois modèles ainsi que leurs tailles : """

baseline_model_accuracy = model.evaluate(
    test_X, test_y, verbose=0)

q_aware_model_accuracy = qat_model.evaluate(
   test_X, test_y, verbose=0)

print('\nBaseline test accuracy:', baseline_model_accuracy[1], 'and size :',size ,'octets')

print('\nAware training accuracy:', q_aware_model_accuracy[1], 'and size :',size_QAT, 'octets')

print('\nPost training accuracy:', accuracy_post, 'and size :', size_post, 'octets')

"""Convertir le modèle - tensorflow for microcontrollers"""

!xxd -i QAT.tflite > model_data.cc

!xxd -i QAT.tflite > model_data.h